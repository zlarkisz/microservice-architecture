# HW-06: Deployment

## E-Commerce Platform

---

## Зміст

1. [CI/CD Pipeline для Payment Service](#1-cicd-pipeline-для-payment-service)
2. [Типи серверів для мікросервісів](#2-типи-серверів-для-мікросервісів)
3. [Canary Deployment для Product Catalog](#3-canary-deployment-для-product-catalog)

---

## Система

E-Commerce платформа складається з 7 мікросервісів:

| Сервіс                       | Відповідальність                            |
| ---------------------------- | ------------------------------------------- |
| **API Gateway**              | Єдина точка входу, routing, rate limiting   |
| **Product Catalog Service**  | Каталог товарів, пошук, фільтрація          |
| **Inventory Service**        | Залишки товарів, резервування               |
| **Order Management Service** | Управління замовленнями, Saga orchestration |
| **Payment Service**          | Обробка платежів                            |
| **User Management Service**  | Аутентифікація, профілі користувачів        |
| **Notification Service**     | Email/push сповіщення                       |

---

## 1. CI/CD Pipeline для Payment Service

### Чому Payment Service?

Payment — найкритичніший сервіс системи. Він працює з реальними грошима, тому pipeline має бути суворішим ніж для звичайних сервісів:

- Будь-який баг = фінансові втрати або репутаційний збиток
- Підпадає під вимоги безпеки (PCI DSS)
- Жодного auto-deploy на production

### Середовища

```
Developer → Git Push → CI Pipeline → Staging → [ручне підтвердження] → Production
```

Три середовища:

- **Dev** — локальна розробка
- **Staging** — автоматичний деплой після merge в main, дзеркало production
- **Production** — тільки після ручного підтвердження Tech Lead / DevOps

### Стадії Pipeline

```
build → test → security → deploy:staging → [manual] → deploy:production
```

#### Чому саме такий порядок:

**build** — спочатку збираємо образ, бо всі наступні стадії працюють з ним

**test** — три типи тестів запускаються паралельно (економія часу):

- `unit-tests` — швидкі, перевіряють бізнес-логіку ізольовано (розрахунок комісій, валідація)
- `integration-tests` — перевіряють роботу з реальною БД і Redis
- `contract-tests` — Pact тести, перевіряють що Payment відповідає саме так як очікує Order Service

**security** — три незалежні перевірки безпеки, теж паралельно:

- `dependency-scan` — `npm audit` перевіряє залежності на CVE вразливості
- `sast` — Semgrep аналізує вихідний код (hardcoded secrets, SQL injection)
- `container-scan` — Trivy сканує Docker образ на вразливості

Всі security job мають `allow_failure: false` — жодну перевірку не можна проігнорувати для Payment.

**deploy-staging** — автоматичний після успішних тестів і security

**deploy-production** — `when: manual`, з'являється кнопка в GitLab UI яку хтось має натиснути вручну

### Ключові рішення

**`$CI_COMMIT_SHA` як тег образу** замість `latest`:

- `latest` не дозволяє відрізнити версії між собою
- SHA дозволяє точно знати який код в якому образі
- Легкий rollback — просто деплоїмо образ з попереднім SHA

**`kubectl rollout status`** після деплою:

- Чекаємо поки всі поди успішно запустяться
- Якщо за timeout не запустились — pipeline падає
- Kubernetes автоматично робить rollback до попередньої версії
- Timeout на production (180s) більший ніж на staging (120s) — на prod більше трафіку, поди довше проходять health checks

**`needs: [deploy-staging]`** для production job:

- Production деплой можливий тільки після успішного staging
- Без цього можна було б натиснути кнопку до того як staging готовий

### Файл конфігурації

Повний `.gitlab-ci.yml` з детальними коментарями до кожного рядку знаходиться у файлі [`.gitlab-ci.yml`](.gitlab-ci.yml).

### Загальний flow

```
MR відкрито     →  build + test + security          (авто)
MR злито в main →  + deploy:staging                 (авто)
Після перевірки →  deploy:production                (ручне)
```

---

## 2. Типи серверів для мікросервісів

### Доступні типи та коли використовувати

| Тип                   | Суть                              | Коли підходить                                                                 |
| --------------------- | --------------------------------- | ------------------------------------------------------------------------------ |
| **Bare Metal**        | Фізичний сервер без віртуалізації | Максимальна продуктивність, передбачуване навантаження, high-frequency trading |
| **VM**                | Віртуальний сервер на гіпервізорі | Ізоляція, гнучкість, legacy системи                                            |
| **Container (K8s)**   | Легкі контейнери з оркестрацією   | Мікросервіси, горизонтальне масштабування, нерівномірний трафік                |
| **Serverless (FaaS)** | Функція запускається по події     | Нерегулярне навантаження, event-driven, платиш тільки за виклики               |
| **Managed Service**   | AWS RDS, ElastiCache тощо         | Коли не хочеш адмініструвати інфраструктуру самостійно                         |

### Чому майже всі сервіси — Kubernetes?

Kubernetes — природній вибір для мікросервісної архітектури:

- **HPA** (Horizontal Pod Autoscaler) — автоматично масштабує під піки трафіку
- **Self-healing** — автоматично перезапускає впалі поди
- **Zero cold start** — поди завжди запущені, latency передбачувана
- **Ізоляція** — кожен сервіс в окремому namespace
- **Rolling updates** — оновлення без downtime

**Bare Metal** відпадає бо негнучкий — замовити і налаштувати фізичний сервер це дні/тижні, платиш завжди навіть вночі коли навантаження мінімальне. Виправданий тільки для баз даних з мільярдами записів або high-frequency trading.

**Serverless** виграє тільки там де навантаження справді нерегулярне і затримка некритична.

### Рекомендації по сервісах

#### API Gateway → Container (K8s)

**Характер навантаження:**

- Весь трафік системи проходить через нього — найвище навантаження
- Постійне навантаження, latency критична
- Stateless — просто маршрутизує запити, нічого не зберігає

**Чому K8s:**

- HPA масштабує автоматично під піки
- Поди завжди запущені — cold start як у Serverless вбив би продуктивність всієї системи
- Єдина точка відмови → K8s автоматично перезапускає впалий под

---

#### Product Catalog Service → Container (K8s)

**Характер навантаження:**

- Read-heavy (80-90% читання)
- Нерівномірний трафік — піки вранці і ввечері (користувачі їдуть на роботу і з роботи)
- Latency критична — повільний каталог = користувач закрив сайт

**Чому K8s:**

- HPA автоматично додає поди під ранковий/вечірній пік і прибирає вночі
- Read-heavy stateless сервіс ідеально масштабується горизонтально
- Можна додати CDN поверх для кешування статичних даних каталогу

---

#### Inventory Service → Container (K8s)

**Характер навантаження:**

- Mix read/write — перевірка залишків + резервування товарів
- Потребує консистентності даних — не можна продати товар якого немає
- Під час розпродажів різкі спайки запитів

**Чому не Serverless:**

- **Cold start** — перший запит після паузи виконується повільно (100-500ms)
- **Консистентність** — при розпродажі сотні функцій одночасно намагаються змінити залишки → race condition, можна продати більше ніж є
- **Distributed locks** (Redis) дуже складно реалізувати в serverless середовищі

**Чому K8s:**

- HPA масштабує під розпродажі
- Стабільне середовище для Redis distributed locks
- Stateful логіка потребує передбачуваного середовища виконання

---

#### Order Management Service → Container (K8s)

**Характер навантаження:**

- Write-heavy — створення та оновлення статусів замовлень
- Складна бізнес-логіка (Saga orchestration)
- Рівномірне навантаження протягом дня
- Надійність критична — втрачене замовлення = пряма фінансова втрата

**Чому K8s:**

- Saga orchestration = складна логіка але stateless оркестратор → добре масштабується
- Рівномірне навантаження → стабільна кількість подів без різких змін
- K8s автоматично перезапускає впалі поди — замовлення не губляться

---

#### Payment Service → Container (K8s)

**Характер навантаження:**

- Критична безпека та надійність
- Помірне але стабільне навантаження
- Затримка неприпустима — користувач не має чекати на підтвердження оплати

**Чому K8s:**

- Ізоляція в окремому namespace — підвищена безпека
- Поди завжди запущені, cold start неприпустимий
- Автоматичний перезапуск при падінні
- Вже налаштований CI/CD через kubectl (`.gitlab-ci.yml`)

---

#### User Management Service → Container (K8s)

**Характер навантаження:**

- Переважно читання — перевірка токенів, завантаження профілів
- Кожен запит до будь-якого сервісу проходить через auth
- Latency критична — уповільнив auth = уповільнив всю систему

**Чому K8s:**

- Auth на кожен запит = постійне навантаження
- Cold start неприпустимий — затримка в auth множиться на всі запити системи
- Горизонтальне масштабування під зростання кількості користувачів

---

#### Notification Service → Serverless (FaaS)

**Характер навантаження:**

- Відправляє email/push після подій (замовлення створено, оплата пройшла)
- Запускається тільки у відповідь на події з черги повідомлень
- Якщо сповіщення прийде на 2 секунди пізніше — некритично
- Вночі майже не працює

**Чому Serverless, а не K8s:**

- **Нерегулярне навантаження** → платиш тільки за реальні виклики, не за idle поди вночі
- **Event-driven** → функція запускається коли прийшла подія, і одразу "засинає"
- **Cold start не страшний** → затримка в 500ms для email/push абсолютно некритична
- З K8s платили б за поди які більшість часу просто чекають подій

---

### Підсумок

| Сервіс           | Тип             | Головна причина                          |
| ---------------- | --------------- | ---------------------------------------- |
| API Gateway      | Container (K8s) | Найвище навантаження, latency критична   |
| Product Catalog  | Container (K8s) | Піки трафіку → HPA, latency критична     |
| Inventory        | Container (K8s) | Distributed locks, консистентність даних |
| Order Management | Container (K8s) | Saga orchestration, надійність           |
| Payment          | Container (K8s) | Безпека, cold start неприпустимий        |
| User Management  | Container (K8s) | Auth на кожен запит, latency критична    |
| Notification     | **Serverless**  | Event-driven, нерегулярне навантаження   |

---

## 3. Canary Deployment для Product Catalog Service

### Що таке Canary Deployment?

Назва походить від практики шахтарів — вони брали канарку в шахту. Якщо в шахті з'являвся газ, канарка гинула першою і шахтарі встигали вийти.

В deployment це означає:

- Випускаємо нову версію не для всіх одразу
- Спочатку малий % користувачів отримує нову версію (5%)
- Спостерігаємо за метриками — помилки, latency, конверсія
- Якщо все ок → поступово збільшуємо % до 100%
- Якщо щось пішло не так → миттєвий rollback, постраждали лише 5%

### Чому Product Catalog?

Product Catalog — ідеальний кандидат для Canary:

- **Великий трафік** — легко розділити користувачів на репрезентативні групи
- **Зміни видимі** — новий алгоритм сортування, фільтрація, UI одразу помітні
- **Некритична помилка** — якщо каталог показав не той порядок товарів, це не фінансова втрата (на відміну від Payment)
- **Вимірювана метрика** — можна порівняти конверсію між v1 і v2

**Сценарій:** розробили новий алгоритм сортування товарів. Хочемо перевірити чи він підвищує конверсію перш ніж викочувати всім.

### Стратегія розподілу трафіку

**Обрана стратегія: випадковий % трафіку зі Sticky Sessions**

Розглянуті альтернативи:

| Стратегія                           | Проблема                                                      |
| ----------------------------------- | ------------------------------------------------------------- |
| За регіоном                         | Різна поведінка користувачів по регіонах — нечесне порівняння |
| За user ID                          | Анонімні користувачі не мають ID, а їх більшість у каталозі   |
| За типом (залогінені/анонімні)      | Залогінені — малий % від трафіку, нерепрезентативна вибірка   |
| **Випадковий % зі sticky sessions** | Репрезентативна вибірка, стабільний досвід користувача        |

**Sticky Sessions — чому це важливо:**

Без sticky sessions користувач може отримати v1 при одному запиті і v2 при наступному. Це заплутує користувача — товари "стрибають" в різному порядку.

Реалізація через cookie:

```
canary=true  → завжди йде на v2
canary=false → завжди йде на v1
немає cookie → рандомно розподіляємо (5% → v2) і встановлюємо cookie
```

### Архітектура

```
Користувач
    |
Ingress Controller (Nginx)
    | перевіряє cookie + розподіляє за вагою
    |
    |-- 95% --> Product Catalog v1 (stable)   [Deployment: catalog-v1]
    |
    +--  5% --> Product Catalog v2 (canary)   [Deployment: catalog-v2]
```

**Чому Ingress Controller (Nginx)?**

Ingress Controller — це компонент Kubernetes який сидить перед усіма сервісами і бачить кожен вхідний запит. Це ідеальне місце для розподілу трафіку бо:

- Бачить всі запити до Product Catalog
- Може читати та встановлювати cookies
- Може розподіляти трафік за вагою (weight-based routing)
- Не потребує змін у коді самого сервісу

### Kubernetes конфігурація

```yaml
# Два окремих Deployment — стабільна і canary версії
apiVersion: apps/v1
kind: Deployment
metadata:
  name: catalog-v1 # Стабільна версія
spec:
  replicas: 9 # 9 подів — отримують 95% трафіку
  template:
    spec:
      containers:
        - name: catalog
          image: catalog-service:v1.0.0
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: catalog-v2 # Canary версія
spec:
  replicas: 1 # 1 под — отримує ~5% трафіку (1 з 10 подів)
  template:
    spec:
      containers:
        - name: catalog
          image: catalog-service:v2.0.0
---
# Ingress з canary анотаціями
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: catalog-canary
  annotations:
    nginx.ingress.kubernetes.io/canary: "true"
    # 5% трафіку йде на canary
    nginx.ingress.kubernetes.io/canary-weight: "5"
    # Sticky session через cookie
    nginx.ingress.kubernetes.io/canary-by-cookie: "canary"
```

### Поступовий Rollout

```
День 1:   5% → v2   Спостерігаємо за базовими метриками (помилки, latency)
День 3:  25% → v2   Якщо метрики ок — збільшуємо
День 5:  50% → v2   Половина користувачів на новій версії
День 7: 100% → v2   Повний rollout, v1 виводимо з експлуатації
```

Між кожним кроком — аналіз метрик. Переходимо далі тільки якщо все в нормі.

### Метрики для прийняття рішення

**Технічні метрики** (моніторимо в Grafana):

- **Error rate** — % помилок не має зрости порівняно з v1
- **Latency (p95, p99)** — час відповіді не має деградувати
- **CPU/Memory** — нова версія не має споживати значно більше ресурсів

**Бізнес метрики** (порівнюємо між групами):

- **Конверсія** — % користувачів які додали товар в корзину
- **CTR** — % кліків на товари з каталогу
- **Час на сторінці** — чи не погіршився UX

### Rollback

Якщо на будь-якому етапі метрики погіршились:

```bash
# Миттєвий rollback — перенаправляємо весь трафік на v1
kubectl patch ingress catalog-canary -p \
  '{"metadata":{"annotations":{"nginx.ingress.kubernetes.io/canary-weight":"0"}}}'

# Видаляємо canary deployment
kubectl delete deployment catalog-v2
```

**Час rollback: ~30 секунд** — саме тому Canary кращий за звичайний деплой. При звичайному деплої rollback це новий деплой старої версії (хвилини). При Canary — просто перемикаємо трафік назад.

### Порівняння з Blue-Green Deployment

|                | Canary                        | Blue-Green                           |
| -------------- | ----------------------------- | ------------------------------------ |
| Ризик          | Мінімальний (5% користувачів) | Середній (миттєве переключення всіх) |
| Rollback       | ~30 секунд                    | ~30 секунд                           |
| Ресурси        | +10% (1 додатковий под)       | +100% (повний дублікат середовища)   |
| A/B тестування | Так                           | Ні                                   |
| Складність     | Середня                       | Низька                               |

Canary — кращий вибір для Product Catalog бо дозволяє одночасно безпечно деплоїти і проводити A/B тест нового алгоритму сортування.
